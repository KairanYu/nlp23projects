# Text Detoxifier（侮辱性语言和谐器） 实验报告

---

## 实验配置

``` code
CPU: Intel(R) Core(TM) i9-10900K CPU @ 3.70GHz
GPU: NVIDIA GeForce RTX 3090(24G) * 1
```

## 实验环境

实验在`Python 3.8.2`环境下运行，具体运行环境可通过`pip install -r requirements.txt`搭建。另外本次实验所使用服务器上的cuda版本为`CUDA 11.3`，在配置环境时需要注意兼容性问题（实验时使用的是`torch 1.12.1+cu113`）。

## 实验步骤

- **训练模型：** 运行`train.sh`：

    ``` code
    python3 mbart_trainer.py \
    --batch_size 16 \
    --max_steps 40000 \
    --learning_rate 1e-5 \
    --output_dir trained_models
    ```

    我们选择微调的模型为`facebook/mbart-large-50`，训练参数初始化如上所示，如果想要调整训练参数，可在`train.sh`中更改。

- **测试模型：** 我们利用`data/english_data/test_toxic_parallel.txt`中的数据来测试训练好的模型，模型会读入测试集中的具有侮辱意味的语言，生成净化和谐后的新句子并写入所调用模型的文件夹下的`test_results.txt`文件中。我们可以通过运行`inference.sh`来实现：

  ``` code
  python3 inference.py \
    --model_path trained_models/mbart_40000_ENG/checkpoint-3000
  ```

- **自定义输入并获得模型输出：** 我们还提供了一个无GPU调用模型的程序`detoxifier.py`，它能够直接接受用户在终端的输入并在终端输出，在这里输入任意一句带有侮辱意味的语言，模型将输出和谐之后的纯净版本。这样，即使在不具备训练条件的本地机器上，我们也能够将模型部署到本地应用。

## 实验结果

通过对比`text_toxic_parallel.txt`和`test_results.txt`中对应的和谐前后的句子，我们可以得出以下结论：

- 我们训练出的模型能够准确识别出具有侮辱意味的词汇，并对这样的词汇进行同义替换
- 在保持语义不改变的层面，模型也具有不错的表现，基本能够保持和谐前后语义的一致性。

我们将两个文件中转换前后的句子整合到了`en_detox_results.xlsx`文件中，以供直观比对。另外，运行不调用GPU的`detoxifier.py`程序的耗时也极短（<10s），证明将模型部署到本地使用具有可行性。

## 有待完善的方面

- 缺少量化的测试指标：目前我们只对和谐前后的句子进行直观、定性的比较来评估模型，而并没有定量分析。实际上，这一点是可以做到的，但需要调用其他的预训练模型来配合实现。考虑到本次实验时间较为紧张，并且由于网络原因调用预训练模型存在不便，故本次实验并没有做定量的模型评估，这一点在之后有条件可以继续实现。

## 参考文献

<https://arxiv.org/abs/2206.02252v1>

## 其他尝试

- 在本次实验中我们尝试了带语义分析的方法(<https://arxiv.org/abs/2209.08207>)，并成功训练且测试了这个模型，但该模型的输入是语义分析后的句子，而对一个句子进行语义分析需要大量额外工作，导致该模型难以部署到本地应用，因此最终放弃了这个模型。
- 本次实验我们还尝试了另外的一些方法（如COUNT(<https://aclanthology.org/2023.findings-emnlp.579/>)，DiffuDetox(<https://arxiv.org/abs/2306.08505>，利用扩散模型)等），但这些方法在复现时遇到了很多环境配置方面的问题（版本不对应/不匹配等），并且这些较新的模型对于算力要求也更高，因此本次实验也没有进一步向目前最前沿的方向探索。

本次实验的题目是一个有趣兼具挑战性的研究方向，十分值得我在本次实验结束后继续研究探索。

## src文件目录

``` bash
src
├── data
│   └── english_data
│       ├── en_data.xlsx
│       └── test_toxic_parallel.txt
├── detoxifier.py
├── inference.py
├── mbart_trainer.py
├── __pycache__
│   └── utils.cpython-38.pyc
├── en_detox_results.xlsx
├── requirements.txt
├── scripts
│   ├── inference.sh
│   ├── run_detox.sh
│   └── train.sh
└── utils.py
 

4 directories, 12 files
（注：由于模型文件过大(6.8G)，最终提交的文件中不包含训练出的checkpoints）
```
